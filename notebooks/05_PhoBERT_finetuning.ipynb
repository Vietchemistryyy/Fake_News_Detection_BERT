{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3757af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CELL 1: Clone Repo\n",
    "# ==============================================================================\n",
    "!git clone https://github.com/Vietchemistryyy/Fake_News_Detection_BERT.git\n",
    "%cd Fake_News_Detection_BERT\n",
    "!ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0584a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CELL 2: Environment Setup\n",
    "# ==============================================================================\n",
    "print(\"=\"*80)\n",
    "print(\"ENVIRONMENT SETUP & VERIFICATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "import os, sys\n",
    "os.chdir(\"/content/Fake_News_Detection_BERT\")\n",
    "sys.path.append(os.getcwd())\n",
    "print(\"üìÅ Working directory:\", os.getcwd())\n",
    "\n",
    "# Test imports\n",
    "try:\n",
    "    import transformers\n",
    "    print(f\"‚úÖ Transformers version: {transformers.__version__}\")\n",
    "    \n",
    "    from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "    print(\"‚úÖ Core transformers imports successful\")\n",
    "    \n",
    "    # Test PhoBERT tokenizer\n",
    "    test_tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")\n",
    "    print(\"‚úÖ PhoBERT tokenizer test successful\")\n",
    "    print(\"\\nüéâ Environment ready for training!\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Import error: {e}\")\n",
    "    print(\"\\nüí° Installing required packages...\")\n",
    "    !pip install -q transformers accelerate datasets torch scikit-learn\n",
    "    print(\"‚úÖ Packages installed. Please restart kernel and run again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ad7d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CELL 3: Complete Imports\n",
    "# ==============================================================================\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"=\"*80)\n",
    "print(\"IMPORTS COMPLETED\")\n",
    "print(\"=\"*80)\n",
    "print(f\"üñ•Ô∏è  Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "print(f\"ü§ñ Model: vinai/phobert-base\")\n",
    "print(f\"üìä Ready to train!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab071381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CELL 4: Mount Google Drive\n",
    "# ==============================================================================\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# T·∫°o th∆∞ m·ª•c l∆∞u model trong Drive\n",
    "MODEL_OUTPUT_DIR = '/content/drive/MyDrive/PhoBERT_VFND'\n",
    "!mkdir -p {MODEL_OUTPUT_DIR}\n",
    "print(f\"‚úÖ Model s·∫Ω ƒë∆∞·ª£c l∆∞u v√†o: {MODEL_OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649a90cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CELL 5: T·∫£i VFND Dataset\n",
    "# ==============================================================================\n",
    "print(\"=\"*80)\n",
    "print(\"DOWNLOADING VFND DATASET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "import requests\n",
    "from io import StringIO\n",
    "import re\n",
    "\n",
    "# URLs (GitHub raw content)\n",
    "FAKE_URL = \"https://raw.githubusercontent.com/WhySchools/VFND-vietnamese-fake-news-datasets/master/fake.csv\"\n",
    "REAL_URL = \"https://raw.githubusercontent.com/WhySchools/VFND-vietnamese-fake-news-datasets/master/real.csv\"\n",
    "\n",
    "print(\"\\nüì• Downloading fake news...\")\n",
    "try:\n",
    "    fake_response = requests.get(FAKE_URL, timeout=30)\n",
    "    fake_response.raise_for_status()\n",
    "    fake_df = pd.read_csv(StringIO(fake_response.text))\n",
    "    fake_df['label'] = 1\n",
    "    print(f\"‚úÖ Downloaded {len(fake_df):,} fake news samples\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error downloading fake.csv: {e}\")\n",
    "    print(\"\\nüí° Alternative: Clone repo v√† load t·ª´ file:\")\n",
    "    print(\"   !git clone https://github.com/WhySchools/VFND-vietnamese-fake-news-datasets.git\")\n",
    "    print(\"   fake_df = pd.read_csv('VFND-vietnamese-fake-news-datasets/fake.csv')\")\n",
    "    raise\n",
    "\n",
    "print(\"\\nÔøΩ  Downloading real news...\")\n",
    "try:\n",
    "    real_response = requests.get(REAL_URL, timeout=30)\n",
    "    real_response.raise_for_status()\n",
    "    real_df = pd.read_csv(StringIO(real_response.text))\n",
    "    real_df['label'] = 0\n",
    "    print(f\"‚úÖ Downloaded {len(real_df):,} real news samples\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error downloading real.csv: {e}\")\n",
    "    print(\"\\nüí° Alternative: Clone repo v√† load t·ª´ file:\")\n",
    "    print(\"   !git clone https://github.com/WhySchools/VFND-vietnamese-fake-news-datasets.git\")\n",
    "    print(\"   real_df = pd.read_csv('VFND-vietnamese-fake-news-datasets/real.csv')\")\n",
    "    raise\n",
    "\n",
    "# Combine\n",
    "df = pd.concat([fake_df, real_df], ignore_index=True)\n",
    "print(f\"\\nüìä Total samples: {len(df):,}\")\n",
    "print(f\"   Fake: {(df['label'] == 1).sum():,} ({(df['label'] == 1).sum() / len(df) * 100:.2f}%)\")\n",
    "print(f\"   Real: {(df['label'] == 0).sum():,} ({(df['label'] == 0).sum() / len(df) * 100:.2f}%)\")\n",
    "\n",
    "# Hi·ªÉn th·ªã columns ƒë·ªÉ bi·∫øt c·ªôt n√†o ch·ª©a content\n",
    "print(f\"\\nüìã Dataset columns: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b071f3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CELL 5B: BACKUP - N·∫øu URLs kh√¥ng ho·∫°t ƒë·ªông (Ch·ªâ ch·∫°y n·∫øu Cell 5 l·ªói)\n",
    "# ==============================================================================\n",
    "# Uncomment v√† ch·∫°y n·∫øu Cell 5 b·ªã l·ªói:\n",
    "\n",
    "# print(\"üì• Using backup method: Clone repo...\")\n",
    "# !git clone https://github.com/WhySchools/VFND-vietnamese-fake-news-datasets.git\n",
    "# \n",
    "# fake_df = pd.read_csv('VFND-vietnamese-fake-news-datasets/fake.csv')\n",
    "# fake_df['label'] = 1\n",
    "# print(f\"‚úÖ Loaded {len(fake_df):,} fake news samples\")\n",
    "# \n",
    "# real_df = pd.read_csv('VFND-vietnamese-fake-news-datasets/real.csv')\n",
    "# real_df['label'] = 0\n",
    "# print(f\"‚úÖ Loaded {len(real_df):,} real news samples\")\n",
    "# \n",
    "# df = pd.concat([fake_df, real_df], ignore_index=True)\n",
    "# print(f\"\\nüìä Total samples: {len(df):,}\")\n",
    "# print(f\"üìã Dataset columns: {df.columns.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac313487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CELL 6: X·ª≠ l√Ω d·ªØ li·ªáu\n",
    "# ==============================================================================\n",
    "print(\"=\"*80)\n",
    "print(\"PROCESSING DATASET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = str(text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'[^\\w\\s\\u00C0-\\u1EF9]', ' ', text)\n",
    "    return ' '.join(text.split()).strip()\n",
    "\n",
    "# T√¨m c·ªôt content\n",
    "content_col = None\n",
    "for col in ['content', 'text', 'article', 'body', 'Content', 'Text']:\n",
    "    if col in df.columns:\n",
    "        content_col = col\n",
    "        break\n",
    "\n",
    "if content_col is None:\n",
    "    content_col = df.columns[0]\n",
    "\n",
    "print(f\"\\nüî§ Using content column: '{content_col}'\")\n",
    "\n",
    "# Clean\n",
    "print(\"\\nüßπ Cleaning text...\")\n",
    "df['cleaned_content'] = df[content_col].apply(clean_text)\n",
    "\n",
    "# Remove empty\n",
    "before_len = len(df)\n",
    "df = df[df['cleaned_content'].str.len() >= 20]\n",
    "print(f\"   Removed {before_len - len(df):,} samples (too short)\")\n",
    "\n",
    "# Remove duplicates\n",
    "before_len = len(df)\n",
    "df = df.drop_duplicates(subset=['cleaned_content'])\n",
    "print(f\"   Removed {before_len - len(df):,} duplicates\")\n",
    "\n",
    "# Shuffle\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"\\n‚úÖ Final dataset: {len(df):,} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6fda0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CELL 7: Chia train/val/test\n",
    "# ==============================================================================\n",
    "print(\"=\"*80)\n",
    "print(\"SPLITTING DATASET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Split\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42, stratify=df['label'])\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df['label'])\n",
    "\n",
    "print(f\"\\n‚úÖ Split completed:\")\n",
    "print(f\"   Train: {len(train_df):,} samples\")\n",
    "print(f\"   Val:   {len(val_df):,} samples\")\n",
    "print(f\"   Test:  {len(test_df):,} samples\")\n",
    "\n",
    "# Check distribution\n",
    "for name, data in [('Train', train_df), ('Val', val_df), ('Test', test_df)]:\n",
    "    fake_pct = (data['label'] == 1).sum() / len(data) * 100\n",
    "    print(f\"   {name:5} - Fake: {fake_pct:5.2f}%, Real: {100-fake_pct:5.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9da7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CELL 8: Load PhoBERT\n",
    "# ==============================================================================\n",
    "print(\"=\"*80)\n",
    "print(\"LOADING PHOBERT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "MODEL_NAME = \"vinai/phobert-base\"\n",
    "MAX_LENGTH = 256\n",
    "\n",
    "print(f\"\\nü§ñ Loading {MODEL_NAME}...\")\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "print(f\"‚úÖ Tokenizer loaded (vocab size: {tokenizer.vocab_size:,})\")\n",
    "\n",
    "# Load model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=2,\n",
    "    problem_type=\"single_label_classification\"\n",
    ")\n",
    "model = model.to(device)\n",
    "print(f\"‚úÖ Model loaded\")\n",
    "print(f\"   Parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f30b067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CELL 9: Chu·∫©n b·ªã Datasets\n",
    "# ==============================================================================\n",
    "print(\"=\"*80)\n",
    "print(\"PREPARING DATASETS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=MAX_LENGTH\n",
    "    )\n",
    "\n",
    "# Create datasets\n",
    "train_data = Dataset.from_dict({\n",
    "    \"text\": train_df[\"cleaned_content\"].tolist(),\n",
    "    \"label\": train_df[\"label\"].tolist()\n",
    "})\n",
    "\n",
    "val_data = Dataset.from_dict({\n",
    "    \"text\": val_df[\"cleaned_content\"].tolist(),\n",
    "    \"label\": val_df[\"label\"].tolist()\n",
    "})\n",
    "\n",
    "test_data = Dataset.from_dict({\n",
    "    \"text\": test_df[\"cleaned_content\"].tolist(),\n",
    "    \"label\": test_df[\"label\"].tolist()\n",
    "})\n",
    "\n",
    "# Tokenize\n",
    "print(\"\\nüî§ Tokenizing...\")\n",
    "train_dataset = train_data.map(tokenize_function, batched=True)\n",
    "val_dataset = val_data.map(tokenize_function, batched=True)\n",
    "test_dataset = test_data.map(tokenize_function, batched=True)\n",
    "\n",
    "# Set format\n",
    "train_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "val_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "test_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "print(f\"‚úÖ Datasets ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c42f1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CELL 10: Training Arguments\n",
    "# ==============================================================================\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=MODEL_OUTPUT_DIR,\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=500,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=500,\n",
    "    save_total_limit=3,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    logging_dir=f\"{MODEL_OUTPUT_DIR}/logs\",\n",
    "    logging_steps=100,\n",
    "    report_to=\"none\",\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    dataloader_num_workers=2,\n",
    "    seed=42,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "print(\"‚öôÔ∏è  Training configuration:\")\n",
    "print(f\"   Epochs: {training_args.num_train_epochs}\")\n",
    "print(f\"   Batch size: {training_args.per_device_train_batch_size}\")\n",
    "print(f\"   Learning rate: {training_args.learning_rate}\")\n",
    "print(f\"   FP16: {training_args.fp16}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb3354a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CELL 11: Metrics Function\n",
    "# ==============================================================================\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, predictions, average='binary'\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Metrics function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c695393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CELL 12: Initialize Trainer\n",
    "# ==============================================================================\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Trainer initialized\")\n",
    "print(\"\\nüöÄ Starting training...\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2598e5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CELL 13: TRAIN! üöÄ\n",
    "# ==============================================================================\n",
    "train_result = trainer.train()\n",
    "\n",
    "print(\"\\n‚úÖ Training completed!\")\n",
    "print(f\"   Training time: {train_result.metrics['train_runtime']:.2f}s\")\n",
    "print(f\"   Training loss: {train_result.metrics['train_loss']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81850a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CELL 14: Evaluate\n",
    "# ==============================================================================\n",
    "print(\"\\nüìä Evaluating on validation set...\")\n",
    "val_results = trainer.evaluate(val_dataset)\n",
    "\n",
    "print(\"\\n‚úÖ Validation Results:\")\n",
    "print(f\"   Accuracy:  {val_results['eval_accuracy']:.4f}\")\n",
    "print(f\"   Precision: {val_results['eval_precision']:.4f}\")\n",
    "print(f\"   Recall:    {val_results['eval_recall']:.4f}\")\n",
    "print(f\"   F1 Score:  {val_results['eval_f1']:.4f}\")\n",
    "\n",
    "print(\"\\nüìä Evaluating on test set...\")\n",
    "test_results = trainer.evaluate(test_dataset)\n",
    "\n",
    "print(\"\\n‚úÖ Test Results:\")\n",
    "print(f\"   Accuracy:  {test_results['eval_accuracy']:.4f}\")\n",
    "print(f\"   Precision: {test_results['eval_precision']:.4f}\")\n",
    "print(f\"   Recall:    {test_results['eval_recall']:.4f}\")\n",
    "print(f\"   F1 Score:  {test_results['eval_f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d1ea56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CELL 15: Confusion Matrix\n",
    "# ==============================================================================\n",
    "predictions = trainer.predict(test_dataset)\n",
    "y_pred = np.argmax(predictions.predictions, axis=1)\n",
    "y_true = test_df['label'].values\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Real', 'Fake'],\n",
    "            yticklabels=['Real', 'Fake'])\n",
    "plt.title('Confusion Matrix - PhoBERT Fine-tuned')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{MODEL_OUTPUT_DIR}/confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Confusion matrix saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5642066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CELL 16: Save Model\n",
    "# ==============================================================================\n",
    "print(\"üíæ Saving model...\")\n",
    "\n",
    "model.save_pretrained(MODEL_OUTPUT_DIR)\n",
    "tokenizer.save_pretrained(MODEL_OUTPUT_DIR)\n",
    "\n",
    "# Save results\n",
    "import json\n",
    "results = {\n",
    "    \"model_name\": MODEL_NAME,\n",
    "    \"max_length\": MAX_LENGTH,\n",
    "    \"training_time\": train_result.metrics['train_runtime'],\n",
    "    \"validation_results\": {\n",
    "        \"accuracy\": float(val_results['eval_accuracy']),\n",
    "        \"precision\": float(val_results['eval_precision']),\n",
    "        \"recall\": float(val_results['eval_recall']),\n",
    "        \"f1\": float(val_results['eval_f1'])\n",
    "    },\n",
    "    \"test_results\": {\n",
    "        \"accuracy\": float(test_results['eval_accuracy']),\n",
    "        \"precision\": float(test_results['eval_precision']),\n",
    "        \"recall\": float(test_results['eval_recall']),\n",
    "        \"f1\": float(test_results['eval_f1'])\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(f'{MODEL_OUTPUT_DIR}/training_results.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Model saved to: {MODEL_OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10bd2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CELL 17: Copy Model sang Drive ƒë·ªÉ download\n",
    "# ==============================================================================\n",
    "print(\"=\"*80)\n",
    "print(\"COPY MODEL TO GOOGLE DRIVE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "import shutil\n",
    "easy_path = '/content/drive/MyDrive/PhoBERT_Model_Download'\n",
    "\n",
    "print(f\"\\nüì¶ Copying model to: {easy_path}\")\n",
    "if os.path.exists(easy_path):\n",
    "    shutil.rmtree(easy_path)\n",
    "shutil.copytree(MODEL_OUTPUT_DIR, easy_path)\n",
    "\n",
    "print(\"\\n‚úÖ Model copied to Google Drive!\")\n",
    "print(f\"\\nüìÅ Location: My Drive/PhoBERT_Model_Download/\")\n",
    "print(f\"\\nüìã Important files:\")\n",
    "print(f\"   ‚úÖ pytorch_model.bin ({os.path.getsize(f'{easy_path}/pytorch_model.bin')/1e6:.1f} MB)\")\n",
    "print(f\"   ‚úÖ config.json\")\n",
    "print(f\"   ‚úÖ vocab.txt\")\n",
    "print(f\"   ‚úÖ training_results.json\")\n",
    "\n",
    "print(\"\\nüí° Download v·ªÅ m√°y:\")\n",
    "print(\"   1. M·ªü Google Drive (web ho·∫∑c desktop)\")\n",
    "print(\"   2. V√†o My Drive/PhoBERT_Model_Download/\")\n",
    "print(\"   3. Right-click ‚Üí Download\")\n",
    "print(\"   4. Copy v√†o: models/PhoBERT_VFND/\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540f0fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CELL 18: Test v·ªõi c√¢u m·∫´u\n",
    "# ==============================================================================\n",
    "def predict_text(text):\n",
    "    model.eval()\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        max_length=MAX_LENGTH,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        probs = torch.softmax(logits, dim=1)[0]\n",
    "        pred_class = torch.argmax(probs).item()\n",
    "    \n",
    "    return {\n",
    "        \"label\": \"Fake\" if pred_class == 1 else \"Real\",\n",
    "        \"confidence\": float(probs[pred_class]),\n",
    "        \"probabilities\": {\n",
    "            \"real\": float(probs[0]),\n",
    "            \"fake\": float(probs[1])\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Test samples\n",
    "test_texts = [\n",
    "    \"Ch√≠nh ph·ªß c√¥ng b·ªë ch√≠nh s√°ch m·ªõi v·ªÅ gi√°o d·ª•c ƒë·∫°i h·ªçc\",\n",
    "    \"Ph√°t hi·ªán thu·ªëc ch·ªØa ung th∆∞ ch·ªâ trong 3 ng√†y, b√°c sƒ© kh√¥ng mu·ªën b·∫°n bi·∫øt!\",\n",
    "    \"Ng√¢n h√†ng Nh√† n∆∞·ªõc ƒëi·ªÅu ch·ªânh l√£i su·∫•t c∆° b·∫£n xu·ªëng 4.5%\",\n",
    "    \"U·ªëng n∆∞·ªõc chanh m·ªói s√°ng gi√∫p gi·∫£m 10kg trong 1 tu·∫ßn!\",\n",
    "]\n",
    "\n",
    "print(\"\\nüß™ Testing with sample texts:\\n\")\n",
    "for i, text in enumerate(test_texts, 1):\n",
    "    result = predict_text(text)\n",
    "    print(f\"{i}. {text[:70]}...\")\n",
    "    print(f\"   Prediction: {result['label']}\")\n",
    "    print(f\"   Confidence: {result['confidence']:.2%}\")\n",
    "    print(f\"   Real: {result['probabilities']['real']:.2%} | Fake: {result['probabilities']['fake']:.2%}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ef9430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CELL 19: Summary\n",
    "# ==============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéâ FINE-TUNING HO√ÄN T·∫§T!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüìÅ Model ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: {MODEL_OUTPUT_DIR}\")\n",
    "print(f\"\\nüìä K·∫øt qu·∫£ Test Set:\")\n",
    "print(f\"   Accuracy:  {test_results['eval_accuracy']:.2%}\")\n",
    "print(f\"   F1 Score:  {test_results['eval_f1']:.4f}\")\n",
    "print(f\"\\nüí° B∆∞·ªõc ti·∫øp theo:\")\n",
    "print(f\"   1. Download model t·ª´ Google Drive\")\n",
    "print(f\"   2. Copy v√†o th∆∞ m·ª•c models/PhoBERT_VFND/\")\n",
    "print(f\"   3. Update api/.env: PHOBERT_MODEL_PATH=../models/PhoBERT_VFND\")\n",
    "print(f\"   4. Restart API server\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107daeea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
