{
  "best_global_step": 11906,
  "best_metric": 0.9228637134027527,
  "best_model_checkpoint": "/content/Fake_News_Detection_BERT/models/roberta/checkpoint-11906",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 11906,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.016798252981689903,
      "grad_norm": 1.3574386835098267,
      "learning_rate": 3.96e-06,
      "loss": 0.6908,
      "step": 100
    },
    {
      "epoch": 0.033596505963379805,
      "grad_norm": 4.171449184417725,
      "learning_rate": 7.960000000000002e-06,
      "loss": 0.4644,
      "step": 200
    },
    {
      "epoch": 0.050394758945069715,
      "grad_norm": 75.26722717285156,
      "learning_rate": 1.196e-05,
      "loss": 0.2624,
      "step": 300
    },
    {
      "epoch": 0.06719301192675961,
      "grad_norm": 25.669513702392578,
      "learning_rate": 1.5960000000000003e-05,
      "loss": 0.2465,
      "step": 400
    },
    {
      "epoch": 0.08399126490844952,
      "grad_norm": 52.53638458251953,
      "learning_rate": 1.9960000000000002e-05,
      "loss": 0.2244,
      "step": 500
    },
    {
      "epoch": 0.10078951789013943,
      "grad_norm": 2.9375123977661133,
      "learning_rate": 1.988593813007662e-05,
      "loss": 0.2199,
      "step": 600
    },
    {
      "epoch": 0.11758777087182933,
      "grad_norm": 0.6368976831436157,
      "learning_rate": 1.9770724120053e-05,
      "loss": 0.2046,
      "step": 700
    },
    {
      "epoch": 0.13438602385351922,
      "grad_norm": 2.5306806564331055,
      "learning_rate": 1.9655510110029382e-05,
      "loss": 0.1817,
      "step": 800
    },
    {
      "epoch": 0.15118427683520913,
      "grad_norm": 0.6802001595497131,
      "learning_rate": 1.9540296100005764e-05,
      "loss": 0.1578,
      "step": 900
    },
    {
      "epoch": 0.16798252981689904,
      "grad_norm": 96.48049926757812,
      "learning_rate": 1.9425082089982145e-05,
      "loss": 0.1651,
      "step": 1000
    },
    {
      "epoch": 0.18478078279858895,
      "grad_norm": 0.703428328037262,
      "learning_rate": 1.9309868079958523e-05,
      "loss": 0.1667,
      "step": 1100
    },
    {
      "epoch": 0.20157903578027886,
      "grad_norm": 0.3322131037712097,
      "learning_rate": 1.9194654069934905e-05,
      "loss": 0.1809,
      "step": 1200
    },
    {
      "epoch": 0.21837728876196877,
      "grad_norm": 22.133697509765625,
      "learning_rate": 1.9079440059911286e-05,
      "loss": 0.1613,
      "step": 1300
    },
    {
      "epoch": 0.23517554174365865,
      "grad_norm": 0.5919082760810852,
      "learning_rate": 1.8964226049887667e-05,
      "loss": 0.1566,
      "step": 1400
    },
    {
      "epoch": 0.2519737947253486,
      "grad_norm": 0.24416638910770416,
      "learning_rate": 1.884901203986405e-05,
      "loss": 0.1608,
      "step": 1500
    },
    {
      "epoch": 0.26877204770703844,
      "grad_norm": 0.4719480276107788,
      "learning_rate": 1.873379802984043e-05,
      "loss": 0.1563,
      "step": 1600
    },
    {
      "epoch": 0.28557030068872835,
      "grad_norm": 0.3649079501628876,
      "learning_rate": 1.861858401981681e-05,
      "loss": 0.1597,
      "step": 1700
    },
    {
      "epoch": 0.30236855367041826,
      "grad_norm": 0.22303135693073273,
      "learning_rate": 1.8503370009793193e-05,
      "loss": 0.1538,
      "step": 1800
    },
    {
      "epoch": 0.31916680665210817,
      "grad_norm": 0.6293780207633972,
      "learning_rate": 1.8388155999769574e-05,
      "loss": 0.1584,
      "step": 1900
    },
    {
      "epoch": 0.3359650596337981,
      "grad_norm": 13.0028076171875,
      "learning_rate": 1.8272941989745952e-05,
      "loss": 0.1373,
      "step": 2000
    },
    {
      "epoch": 0.352763312615488,
      "grad_norm": 6.577064037322998,
      "learning_rate": 1.8157727979722333e-05,
      "loss": 0.1517,
      "step": 2100
    },
    {
      "epoch": 0.3695615655971779,
      "grad_norm": 0.28930094838142395,
      "learning_rate": 1.8042513969698715e-05,
      "loss": 0.1622,
      "step": 2200
    },
    {
      "epoch": 0.3863598185788678,
      "grad_norm": 90.03367614746094,
      "learning_rate": 1.7927299959675096e-05,
      "loss": 0.1475,
      "step": 2300
    },
    {
      "epoch": 0.4031580715605577,
      "grad_norm": 0.8170238733291626,
      "learning_rate": 1.7812085949651477e-05,
      "loss": 0.1521,
      "step": 2400
    },
    {
      "epoch": 0.4199563245422476,
      "grad_norm": 0.39494115114212036,
      "learning_rate": 1.769687193962786e-05,
      "loss": 0.145,
      "step": 2500
    },
    {
      "epoch": 0.43675457752393754,
      "grad_norm": 0.014784428291022778,
      "learning_rate": 1.758165792960424e-05,
      "loss": 0.1301,
      "step": 2600
    },
    {
      "epoch": 0.4535528305056274,
      "grad_norm": 0.2660031318664551,
      "learning_rate": 1.746644391958062e-05,
      "loss": 0.1435,
      "step": 2700
    },
    {
      "epoch": 0.4703510834873173,
      "grad_norm": 1.1211305856704712,
      "learning_rate": 1.7351229909557003e-05,
      "loss": 0.1483,
      "step": 2800
    },
    {
      "epoch": 0.4871493364690072,
      "grad_norm": 0.3476317524909973,
      "learning_rate": 1.7236015899533384e-05,
      "loss": 0.1217,
      "step": 2900
    },
    {
      "epoch": 0.5039475894506972,
      "grad_norm": 9.149419784545898,
      "learning_rate": 1.7120801889509766e-05,
      "loss": 0.1405,
      "step": 3000
    },
    {
      "epoch": 0.5207458424323871,
      "grad_norm": 0.5118404030799866,
      "learning_rate": 1.7005587879486147e-05,
      "loss": 0.13,
      "step": 3100
    },
    {
      "epoch": 0.5375440954140769,
      "grad_norm": 0.6966734528541565,
      "learning_rate": 1.689037386946253e-05,
      "loss": 0.1313,
      "step": 3200
    },
    {
      "epoch": 0.5543423483957668,
      "grad_norm": 0.033124614506959915,
      "learning_rate": 1.677515985943891e-05,
      "loss": 0.1433,
      "step": 3300
    },
    {
      "epoch": 0.5711406013774567,
      "grad_norm": 0.4726916551589966,
      "learning_rate": 1.665994584941529e-05,
      "loss": 0.1478,
      "step": 3400
    },
    {
      "epoch": 0.5879388543591466,
      "grad_norm": 0.38142040371894836,
      "learning_rate": 1.6544731839391672e-05,
      "loss": 0.1137,
      "step": 3500
    },
    {
      "epoch": 0.6047371073408365,
      "grad_norm": 1.011608600616455,
      "learning_rate": 1.6429517829368054e-05,
      "loss": 0.1482,
      "step": 3600
    },
    {
      "epoch": 0.6215353603225264,
      "grad_norm": 0.89237380027771,
      "learning_rate": 1.6314303819344432e-05,
      "loss": 0.122,
      "step": 3700
    },
    {
      "epoch": 0.6383336133042163,
      "grad_norm": 0.4230078458786011,
      "learning_rate": 1.6199089809320813e-05,
      "loss": 0.1291,
      "step": 3800
    },
    {
      "epoch": 0.6551318662859063,
      "grad_norm": 0.2142474502325058,
      "learning_rate": 1.6083875799297194e-05,
      "loss": 0.1453,
      "step": 3900
    },
    {
      "epoch": 0.6719301192675962,
      "grad_norm": 0.5670766234397888,
      "learning_rate": 1.5968661789273576e-05,
      "loss": 0.1159,
      "step": 4000
    },
    {
      "epoch": 0.6887283722492861,
      "grad_norm": 1.772889494895935,
      "learning_rate": 1.5853447779249957e-05,
      "loss": 0.1433,
      "step": 4100
    },
    {
      "epoch": 0.705526625230976,
      "grad_norm": 0.7928798198699951,
      "learning_rate": 1.573823376922634e-05,
      "loss": 0.161,
      "step": 4200
    },
    {
      "epoch": 0.7223248782126659,
      "grad_norm": 0.5172377228736877,
      "learning_rate": 1.562301975920272e-05,
      "loss": 0.1331,
      "step": 4300
    },
    {
      "epoch": 0.7391231311943558,
      "grad_norm": 0.8079434633255005,
      "learning_rate": 1.55078057491791e-05,
      "loss": 0.1429,
      "step": 4400
    },
    {
      "epoch": 0.7559213841760457,
      "grad_norm": 0.37731683254241943,
      "learning_rate": 1.5392591739155483e-05,
      "loss": 0.1314,
      "step": 4500
    },
    {
      "epoch": 0.7727196371577356,
      "grad_norm": 0.4014948606491089,
      "learning_rate": 1.5277377729131864e-05,
      "loss": 0.1531,
      "step": 4600
    },
    {
      "epoch": 0.7895178901394255,
      "grad_norm": 9.907228469848633,
      "learning_rate": 1.5162163719108245e-05,
      "loss": 0.1353,
      "step": 4700
    },
    {
      "epoch": 0.8063161431211154,
      "grad_norm": 0.5090131163597107,
      "learning_rate": 1.5046949709084627e-05,
      "loss": 0.1472,
      "step": 4800
    },
    {
      "epoch": 0.8231143961028053,
      "grad_norm": 0.03922661766409874,
      "learning_rate": 1.4931735699061008e-05,
      "loss": 0.1423,
      "step": 4900
    },
    {
      "epoch": 0.8399126490844953,
      "grad_norm": 103.65008544921875,
      "learning_rate": 1.481652168903739e-05,
      "loss": 0.1343,
      "step": 5000
    },
    {
      "epoch": 0.8567109020661852,
      "grad_norm": 0.6562496423721313,
      "learning_rate": 1.4701307679013769e-05,
      "loss": 0.1182,
      "step": 5100
    },
    {
      "epoch": 0.8735091550478751,
      "grad_norm": 0.5433423519134521,
      "learning_rate": 1.458609366899015e-05,
      "loss": 0.1122,
      "step": 5200
    },
    {
      "epoch": 0.8903074080295649,
      "grad_norm": 0.5130266547203064,
      "learning_rate": 1.4470879658966532e-05,
      "loss": 0.1444,
      "step": 5300
    },
    {
      "epoch": 0.9071056610112548,
      "grad_norm": 0.8177972435951233,
      "learning_rate": 1.4355665648942913e-05,
      "loss": 0.1383,
      "step": 5400
    },
    {
      "epoch": 0.9239039139929447,
      "grad_norm": 0.44132405519485474,
      "learning_rate": 1.4240451638919295e-05,
      "loss": 0.1191,
      "step": 5500
    },
    {
      "epoch": 0.9407021669746346,
      "grad_norm": 0.7180797457695007,
      "learning_rate": 1.4125237628895674e-05,
      "loss": 0.1297,
      "step": 5600
    },
    {
      "epoch": 0.9575004199563245,
      "grad_norm": 7.994642734527588,
      "learning_rate": 1.4010023618872056e-05,
      "loss": 0.1334,
      "step": 5700
    },
    {
      "epoch": 0.9742986729380144,
      "grad_norm": 0.9587738513946533,
      "learning_rate": 1.3894809608848437e-05,
      "loss": 0.1188,
      "step": 5800
    },
    {
      "epoch": 0.9910969259197043,
      "grad_norm": 0.685111403465271,
      "learning_rate": 1.3779595598824818e-05,
      "loss": 0.1243,
      "step": 5900
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.919594296633838,
      "eval_f1": 0.9195383732040855,
      "eval_loss": 0.12875071167945862,
      "eval_precision": 0.9289955939363913,
      "eval_recall": 0.919594296633838,
      "eval_runtime": 73.0625,
      "eval_samples_per_second": 279.336,
      "eval_steps_per_second": 17.464,
      "step": 5953
    },
    {
      "epoch": 1.0078951789013944,
      "grad_norm": 0.5609166622161865,
      "learning_rate": 1.3664381588801198e-05,
      "loss": 0.1304,
      "step": 6000
    },
    {
      "epoch": 1.0246934318830843,
      "grad_norm": 0.494316041469574,
      "learning_rate": 1.354916757877758e-05,
      "loss": 0.147,
      "step": 6100
    },
    {
      "epoch": 1.0414916848647742,
      "grad_norm": 0.8391098976135254,
      "learning_rate": 1.343395356875396e-05,
      "loss": 0.1168,
      "step": 6200
    },
    {
      "epoch": 1.0582899378464639,
      "grad_norm": 0.4000500738620758,
      "learning_rate": 1.3318739558730342e-05,
      "loss": 0.13,
      "step": 6300
    },
    {
      "epoch": 1.0750881908281538,
      "grad_norm": 0.1476665586233139,
      "learning_rate": 1.3203525548706723e-05,
      "loss": 0.1241,
      "step": 6400
    },
    {
      "epoch": 1.0918864438098437,
      "grad_norm": 0.6630142331123352,
      "learning_rate": 1.3088311538683105e-05,
      "loss": 0.1103,
      "step": 6500
    },
    {
      "epoch": 1.1086846967915336,
      "grad_norm": 0.371446818113327,
      "learning_rate": 1.2973097528659486e-05,
      "loss": 0.1272,
      "step": 6600
    },
    {
      "epoch": 1.1254829497732235,
      "grad_norm": 0.4020150601863861,
      "learning_rate": 1.2857883518635868e-05,
      "loss": 0.1251,
      "step": 6700
    },
    {
      "epoch": 1.1422812027549134,
      "grad_norm": 0.35234150290489197,
      "learning_rate": 1.2742669508612249e-05,
      "loss": 0.1311,
      "step": 6800
    },
    {
      "epoch": 1.1590794557366033,
      "grad_norm": 0.5804144144058228,
      "learning_rate": 1.262745549858863e-05,
      "loss": 0.1254,
      "step": 6900
    },
    {
      "epoch": 1.1758777087182932,
      "grad_norm": 0.6131207942962646,
      "learning_rate": 1.2512241488565012e-05,
      "loss": 0.1184,
      "step": 7000
    },
    {
      "epoch": 1.1926759616999831,
      "grad_norm": 0.5789142847061157,
      "learning_rate": 1.2397027478541393e-05,
      "loss": 0.1214,
      "step": 7100
    },
    {
      "epoch": 1.209474214681673,
      "grad_norm": 0.6624411940574646,
      "learning_rate": 1.2281813468517774e-05,
      "loss": 0.1216,
      "step": 7200
    },
    {
      "epoch": 1.226272467663363,
      "grad_norm": 0.18570655584335327,
      "learning_rate": 1.2166599458494156e-05,
      "loss": 0.1043,
      "step": 7300
    },
    {
      "epoch": 1.2430707206450529,
      "grad_norm": 7.035651206970215,
      "learning_rate": 1.2051385448470534e-05,
      "loss": 0.136,
      "step": 7400
    },
    {
      "epoch": 1.2598689736267428,
      "grad_norm": 5.405607223510742,
      "learning_rate": 1.1936171438446915e-05,
      "loss": 0.1253,
      "step": 7500
    },
    {
      "epoch": 1.2766672266084327,
      "grad_norm": 0.18667708337306976,
      "learning_rate": 1.1820957428423296e-05,
      "loss": 0.1067,
      "step": 7600
    },
    {
      "epoch": 1.2934654795901226,
      "grad_norm": 0.7001132965087891,
      "learning_rate": 1.1705743418399678e-05,
      "loss": 0.1324,
      "step": 7700
    },
    {
      "epoch": 1.3102637325718125,
      "grad_norm": 1.795397400856018,
      "learning_rate": 1.1590529408376059e-05,
      "loss": 0.1204,
      "step": 7800
    },
    {
      "epoch": 1.3270619855535024,
      "grad_norm": 0.7026425004005432,
      "learning_rate": 1.147531539835244e-05,
      "loss": 0.106,
      "step": 7900
    },
    {
      "epoch": 1.3438602385351923,
      "grad_norm": 60.78010940551758,
      "learning_rate": 1.1360101388328822e-05,
      "loss": 0.1227,
      "step": 8000
    },
    {
      "epoch": 1.3606584915168822,
      "grad_norm": 0.4492395520210266,
      "learning_rate": 1.1244887378305203e-05,
      "loss": 0.1237,
      "step": 8100
    },
    {
      "epoch": 1.3774567444985721,
      "grad_norm": 0.5143510103225708,
      "learning_rate": 1.1129673368281585e-05,
      "loss": 0.1318,
      "step": 8200
    },
    {
      "epoch": 1.394254997480262,
      "grad_norm": 0.6220546364784241,
      "learning_rate": 1.1014459358257966e-05,
      "loss": 0.1307,
      "step": 8300
    },
    {
      "epoch": 1.411053250461952,
      "grad_norm": 0.7897548675537109,
      "learning_rate": 1.0899245348234346e-05,
      "loss": 0.1141,
      "step": 8400
    },
    {
      "epoch": 1.4278515034436419,
      "grad_norm": 0.6817178726196289,
      "learning_rate": 1.0784031338210727e-05,
      "loss": 0.1037,
      "step": 8500
    },
    {
      "epoch": 1.4446497564253318,
      "grad_norm": 0.7920197248458862,
      "learning_rate": 1.0668817328187108e-05,
      "loss": 0.1242,
      "step": 8600
    },
    {
      "epoch": 1.4614480094070217,
      "grad_norm": 0.19806011021137238,
      "learning_rate": 1.055360331816349e-05,
      "loss": 0.126,
      "step": 8700
    },
    {
      "epoch": 1.4782462623887116,
      "grad_norm": 0.31934642791748047,
      "learning_rate": 1.0438389308139871e-05,
      "loss": 0.1174,
      "step": 8800
    },
    {
      "epoch": 1.4950445153704015,
      "grad_norm": 0.3525156080722809,
      "learning_rate": 1.0323175298116252e-05,
      "loss": 0.1099,
      "step": 8900
    },
    {
      "epoch": 1.5118427683520914,
      "grad_norm": 67.05008697509766,
      "learning_rate": 1.0207961288092634e-05,
      "loss": 0.1176,
      "step": 9000
    },
    {
      "epoch": 1.5286410213337813,
      "grad_norm": 0.4635601043701172,
      "learning_rate": 1.0092747278069015e-05,
      "loss": 0.1283,
      "step": 9100
    },
    {
      "epoch": 1.5454392743154712,
      "grad_norm": 0.6995489597320557,
      "learning_rate": 9.977533268045395e-06,
      "loss": 0.104,
      "step": 9200
    },
    {
      "epoch": 1.5622375272971611,
      "grad_norm": 0.6488173604011536,
      "learning_rate": 9.862319258021776e-06,
      "loss": 0.1212,
      "step": 9300
    },
    {
      "epoch": 1.579035780278851,
      "grad_norm": 20.4022274017334,
      "learning_rate": 9.747105247998157e-06,
      "loss": 0.1274,
      "step": 9400
    },
    {
      "epoch": 1.595834033260541,
      "grad_norm": 0.3441295027732849,
      "learning_rate": 9.631891237974539e-06,
      "loss": 0.1244,
      "step": 9500
    },
    {
      "epoch": 1.6126322862422309,
      "grad_norm": 0.3305962085723877,
      "learning_rate": 9.51667722795092e-06,
      "loss": 0.1268,
      "step": 9600
    },
    {
      "epoch": 1.6294305392239208,
      "grad_norm": 0.6754300594329834,
      "learning_rate": 9.4014632179273e-06,
      "loss": 0.1015,
      "step": 9700
    },
    {
      "epoch": 1.6462287922056107,
      "grad_norm": 0.7614725232124329,
      "learning_rate": 9.286249207903681e-06,
      "loss": 0.1185,
      "step": 9800
    },
    {
      "epoch": 1.6630270451873006,
      "grad_norm": 0.5402311086654663,
      "learning_rate": 9.171035197880063e-06,
      "loss": 0.1145,
      "step": 9900
    },
    {
      "epoch": 1.6798252981689905,
      "grad_norm": 0.3548337519168854,
      "learning_rate": 9.055821187856444e-06,
      "loss": 0.1084,
      "step": 10000
    },
    {
      "epoch": 1.6966235511506804,
      "grad_norm": 0.4132973551750183,
      "learning_rate": 8.940607177832825e-06,
      "loss": 0.1293,
      "step": 10100
    },
    {
      "epoch": 1.7134218041323703,
      "grad_norm": 0.026497887447476387,
      "learning_rate": 8.825393167809207e-06,
      "loss": 0.1263,
      "step": 10200
    },
    {
      "epoch": 1.7302200571140602,
      "grad_norm": 0.5230847001075745,
      "learning_rate": 8.710179157785588e-06,
      "loss": 0.1207,
      "step": 10300
    },
    {
      "epoch": 1.7470183100957501,
      "grad_norm": 0.3136667013168335,
      "learning_rate": 8.59496514776197e-06,
      "loss": 0.1185,
      "step": 10400
    },
    {
      "epoch": 1.76381656307744,
      "grad_norm": 0.011663684621453285,
      "learning_rate": 8.47975113773835e-06,
      "loss": 0.1105,
      "step": 10500
    },
    {
      "epoch": 1.78061481605913,
      "grad_norm": 0.1455824077129364,
      "learning_rate": 8.36453712771473e-06,
      "loss": 0.1145,
      "step": 10600
    },
    {
      "epoch": 1.7974130690408199,
      "grad_norm": 0.6718584299087524,
      "learning_rate": 8.249323117691112e-06,
      "loss": 0.1073,
      "step": 10700
    },
    {
      "epoch": 1.8142113220225098,
      "grad_norm": 0.4036037027835846,
      "learning_rate": 8.134109107667493e-06,
      "loss": 0.1121,
      "step": 10800
    },
    {
      "epoch": 1.8310095750041997,
      "grad_norm": 0.5689607858657837,
      "learning_rate": 8.018895097643875e-06,
      "loss": 0.1159,
      "step": 10900
    },
    {
      "epoch": 1.8478078279858896,
      "grad_norm": 0.40196317434310913,
      "learning_rate": 7.903681087620256e-06,
      "loss": 0.1112,
      "step": 11000
    },
    {
      "epoch": 1.8646060809675795,
      "grad_norm": 69.3989486694336,
      "learning_rate": 7.788467077596637e-06,
      "loss": 0.1108,
      "step": 11100
    },
    {
      "epoch": 1.8814043339492694,
      "grad_norm": 0.4014321565628052,
      "learning_rate": 7.673253067573017e-06,
      "loss": 0.1169,
      "step": 11200
    },
    {
      "epoch": 1.8982025869309593,
      "grad_norm": 0.5729746222496033,
      "learning_rate": 7.558039057549399e-06,
      "loss": 0.125,
      "step": 11300
    },
    {
      "epoch": 1.9150008399126492,
      "grad_norm": 0.8076666593551636,
      "learning_rate": 7.4428250475257805e-06,
      "loss": 0.1288,
      "step": 11400
    },
    {
      "epoch": 1.9317990928943392,
      "grad_norm": 0.7774714827537537,
      "learning_rate": 7.327611037502161e-06,
      "loss": 0.1053,
      "step": 11500
    },
    {
      "epoch": 1.9485973458760288,
      "grad_norm": 1.27263605594635,
      "learning_rate": 7.2123970274785415e-06,
      "loss": 0.125,
      "step": 11600
    },
    {
      "epoch": 1.9653955988577188,
      "grad_norm": 0.4962402880191803,
      "learning_rate": 7.097183017454923e-06,
      "loss": 0.1059,
      "step": 11700
    },
    {
      "epoch": 1.9821938518394087,
      "grad_norm": 0.8065475225448608,
      "learning_rate": 6.981969007431304e-06,
      "loss": 0.1294,
      "step": 11800
    },
    {
      "epoch": 1.9989921048210986,
      "grad_norm": 0.01177749503403902,
      "learning_rate": 6.866754997407686e-06,
      "loss": 0.1181,
      "step": 11900
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.923612131902592,
      "eval_f1": 0.9228637134027527,
      "eval_loss": 0.12379146367311478,
      "eval_precision": 0.9320431324614706,
      "eval_recall": 0.923612131902592,
      "eval_runtime": 72.6301,
      "eval_samples_per_second": 280.999,
      "eval_steps_per_second": 17.568,
      "step": 11906
    }
  ],
  "logging_steps": 100,
  "max_steps": 17859,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.505974935670784e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
